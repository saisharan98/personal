{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logisticregression_practice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiBku6SFeaC9"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import seaborn as sns\r\n",
        "sns.set(style=\"white\")\r\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\r\n",
        "\r\n",
        "\r\n",
        "data = pd.read_csv('/content/banking.csv') #Subcription data, want to predict if a customer will subcribe\r\n",
        "print(data.head(0))\r\n",
        "#data['education'].unique()\r\n",
        "\r\n",
        "#This data contains 3 instances of \"Basic\" education, it has been combined into one\r\n",
        "data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\r\n",
        "data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\r\n",
        "data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])\r\n",
        "\r\n",
        "#Ratio of output values - highly uneven\r\n",
        "count_0 = len(data[data['y'] == 0]) #Number of 0 subcriptions\r\n",
        "count_1 = len(data[data['y'] == 1]) #Number of 1 subcriptions\r\n",
        "percent_0 = np.round(count_0/(count_0 + count_1)*100,2)\r\n",
        "percent_1 = np.round(count_1/(count_0 + count_1)*100,2) \r\n",
        "# plt.figure(1, figsize=(7,7))\r\n",
        "# sns.countplot(x='y', data=data)\r\n",
        "# plt.title(\"Number of Yes/No subscriptions\")\r\n",
        "\r\n",
        "#Data Exploration\r\n",
        "(data.groupby('age').mean())\r\n",
        "(data.groupby('y').mean())\r\n",
        "(data.groupby('job').mean())\r\n",
        "(data.groupby('education').mean())\r\n",
        "# plt.figure(2, figsize=(5,5))\r\n",
        "# pd.crosstab(data.job, data.y).plot(kind = 'bar') #plotting percetage of subcriptions per job\r\n",
        "# pd.crosstab(data.education, data.y).plot(kind = 'bar') #plotting percetage of subcriptions per education level\r\n",
        "# pd.crosstab(data.marital, data.y).plot(kind = 'bar') #plotting percetage of subcriptions per age\r\n",
        "\r\n",
        "#Create dummy variables- making training data\r\n",
        "cat_vars=data[['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']]\r\n",
        "cat_list = pd.get_dummies(cat_vars, drop_first=True)\r\n",
        "data=data.join(cat_list)\r\n",
        "data=data[[i for i in data if i not in cat_vars]]\r\n",
        "y=data[['y']]\r\n",
        "x=data[[i for i in data if i not in y]]\r\n",
        "\r\n",
        "#Since yes/no ratio is highly unbalance, use SMOTE to sample the no subscriptions\r\n",
        "# X = x.loc[:, x.columns != 'y']\r\n",
        "# y = y.loc[:, y.columns == 'y']\r\n",
        "from imblearn.over_sampling import SMOTE\r\n",
        "smote = SMOTE(random_state=0)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\r\n",
        "columns = X_train.columns\r\n",
        "os_data_X,os_data_y=smote.fit_sample(X_train, y_train)\r\n",
        "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\r\n",
        "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\r\n",
        "\r\n",
        "\r\n",
        "# print(\"length of oversampled data is \",len(os_data_X))\r\n",
        "# print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\r\n",
        "# print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\r\n",
        "# print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\r\n",
        "# print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22FoagDKpX9F"
      },
      "source": [
        "#feature selection using RFE\r\n",
        "data_final_vars=x.columns.values.tolist()\r\n",
        "y=['y']\r\n",
        "X=[i for i in data_final_vars if i not in y]\r\n",
        "from sklearn.feature_selection import RFE\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "logreg = LogisticRegression()\r\n",
        "rfe = RFE(logreg, 20)\r\n",
        "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlzxUJQQUoss",
        "outputId": "987b72ad-3594-4c3c-d238-d3afd7e7edca"
      },
      "source": [
        "#print(rfe.support_)\r\n",
        "#print(rfe.ranking_)\r\n",
        "cols = x.columns[np.where(rfe.support_)]\r\n",
        "X=os_data_X[cols]\r\n",
        "y=os_data_y['y']\r\n",
        "import statsmodels.api as sm\r\n",
        "logit_model=sm.Logit(y,X)\r\n",
        "result=logit_model.fit()\r\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.545359\n",
            "         Iterations 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IFZxlnuBsA2",
        "outputId": "8e0e1468-5b1e-46b3-89d9-ab3d680df4ef"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn import metrics\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\r\n",
        "logreg = LogisticRegression()\r\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    }
  ]
}